{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.figure-eight.com/data-for-everyone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install requests\n",
    "import requests\n",
    "\n",
    "# url = 'https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2016/03/Apple-Twitter-Sentiment-DFE.csv'\n",
    "url = 'https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2016/03/Airline-Sentiment-2-w-AA.csv'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "df = pd.read_csv(StringIO(r.text), sep=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
       "       '_last_judgment_at', 'airline_sentiment',\n",
       "       'airline_sentiment:confidence', 'negativereason',\n",
       "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
       "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
       "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.626913\n",
       "neutral     0.211680\n",
       "positive    0.161407\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts() / df['airline_sentiment'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Service Issue         0.198770\n",
       "Late Flight                    0.113730\n",
       "Can't Tell                     0.081284\n",
       "Cancelled Flight               0.057855\n",
       "Lost Luggage                   0.049454\n",
       "Bad Flight                     0.039617\n",
       "Flight Booking Problems        0.036134\n",
       "Flight Attendant Complaints    0.032855\n",
       "longlines                      0.012158\n",
       "Damaged Luggage                0.005055\n",
       "Name: negativereason, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negativereason'].value_counts() / df['airline_sentiment'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>@JetBlue im still waiting??? No answer!!</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14438</th>\n",
       "      <td>@AmericanAir I will thank you. What do I do if I can't get through and my flight on hold Cancelled Flights?</td>\n",
       "      <td>American</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>@JetBlue have a cpap machine for sleep apnea. Is this OK to carry on if I also have a small bag for clothes?</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>@USAirways My bags were supposed to be delivered to NYC last night (missing since Thurs) but are not here. Can someo...</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>@JetBlue also. My party { me and my sister and mom} are on three separate reservations. Will TSA lets us go through ...</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>@SouthwestAir Thanks for making good on @PoteetTJ 's Cancelled Flightled flight.</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>@JetBlue i am here - what is your resolution?</td>\n",
       "      <td>Delta</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>@united That made me so mad, but then I called the bag number, and that person was helpful and told me where the bag...</td>\n",
       "      <td>United</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>@VirginAmerica is saving my sanity right now: http://t.co/ELtBOLjUl9</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>@united or frontier ... http://t.co/n8WiNFu6C5</td>\n",
       "      <td>United</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>@united from MEX NRT (dates TBD) but I'm getting a 200 to 300 USD difference in my quotations through September when...</td>\n",
       "      <td>United</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>@JetBlue Indeed. I don't know what's going on in Pittsburgh that weekend, but, it's drawing a crowd via JetBlue!</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>I've been trying to set up my phone interview for days, and hoping the position won't be filled because the link doe...</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>@JetBlue thanks for the response. Just been waiting for 5 hours and really frustrated. Seems like no one at JetBlue ...</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>@AmericanAir There are only 24 hours to Cancelled Flight or change itineraries booked online and that 24 hours is ju...</td>\n",
       "      <td>American</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>@SouthwestAir I am trying to change a ticket for travel on Monday that cannot be changed online. Anyway faster than ...</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12575</th>\n",
       "      <td>@AmericanAir gate agents disappeared and customer service agents were miserable and unhelpful. #letdown #neveragain</td>\n",
       "      <td>American</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>@united it's highly unprofessional for you to overbook a flight by 12 seats &amp;amp;feel that I should rearrange my sch...</td>\n",
       "      <td>United</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>@JetBlue thanks!! Great service in #T5 already! #lovejetBlue</td>\n",
       "      <td>Delta</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14352</th>\n",
       "      <td>@AmericanAir there's a direct from Miami w a seat but u rebooked niece Tuesday. Can't get through on phones? #custom...</td>\n",
       "      <td>American</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          text  \\\n",
       "7303                                                                                  @JetBlue im still waiting??? No answer!!   \n",
       "14438              @AmericanAir I will thank you. What do I do if I can't get through and my flight on hold Cancelled Flights?   \n",
       "7592              @JetBlue have a cpap machine for sleep apnea. Is this OK to carry on if I also have a small bag for clothes?   \n",
       "10207  @USAirways My bags were supposed to be delivered to NYC last night (missing since Thurs) but are not here. Can someo...   \n",
       "7057   @JetBlue also. My party { me and my sister and mom} are on three separate reservations. Will TSA lets us go through ...   \n",
       "5139                                          @SouthwestAir Thanks for making good on @PoteetTJ 's Cancelled Flightled flight.   \n",
       "8371                                                                             @JetBlue i am here - what is your resolution?   \n",
       "3973   @united That made me so mad, but then I called the bag number, and that person was helpful and told me where the bag...   \n",
       "309                                                       @VirginAmerica is saving my sanity right now: http://t.co/ELtBOLjUl9   \n",
       "2798                                                                            @united or frontier ... http://t.co/n8WiNFu6C5   \n",
       "1099   @united from MEX NRT (dates TBD) but I'm getting a 200 to 300 USD difference in my quotations through September when...   \n",
       "7185          @JetBlue Indeed. I don't know what's going on in Pittsburgh that weekend, but, it's drawing a crowd via JetBlue!   \n",
       "9759   I've been trying to set up my phone interview for days, and hoping the position won't be filled because the link doe...   \n",
       "7349   @JetBlue thanks for the response. Just been waiting for 5 hours and really frustrated. Seems like no one at JetBlue ...   \n",
       "12600  @AmericanAir There are only 24 hours to Cancelled Flight or change itineraries booked online and that 24 hours is ju...   \n",
       "5298   @SouthwestAir I am trying to change a ticket for travel on Monday that cannot be changed online. Anyway faster than ...   \n",
       "12575      @AmericanAir gate agents disappeared and customer service agents were miserable and unhelpful. #letdown #neveragain   \n",
       "797    @united it's highly unprofessional for you to overbook a flight by 12 seats &amp;feel that I should rearrange my sch...   \n",
       "8925                                                              @JetBlue thanks!! Great service in #T5 already! #lovejetBlue   \n",
       "14352  @AmericanAir there's a direct from Miami w a seat but u rebooked niece Tuesday. Can't get through on phones? #custom...   \n",
       "\n",
       "              airline  airline_sentiment:confidence airline_sentiment  \n",
       "7303            Delta                        1.0000          negative  \n",
       "14438        American                        0.7026           neutral  \n",
       "7592            Delta                        1.0000           neutral  \n",
       "10207      US Airways                        1.0000          negative  \n",
       "7057            Delta                        1.0000           neutral  \n",
       "5139        Southwest                        0.6680          positive  \n",
       "8371            Delta                        0.6201          negative  \n",
       "3973           United                        0.6301          positive  \n",
       "309    Virgin America                        0.3750           neutral  \n",
       "2798           United                        1.0000           neutral  \n",
       "1099           United                        0.6775          negative  \n",
       "7185            Delta                        1.0000           neutral  \n",
       "9759       US Airways                        1.0000          negative  \n",
       "7349            Delta                        1.0000          negative  \n",
       "12600        American                        1.0000          negative  \n",
       "5298        Southwest                        0.6737          negative  \n",
       "12575        American                        1.0000          negative  \n",
       "797            United                        1.0000          negative  \n",
       "8925            Delta                        1.0000          positive  \n",
       "14352        American                        1.0000          negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'airline', 'airline_sentiment:confidence', 'airline_sentiment']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(df_train['airline_sentiment'])\n",
    "y_test = le.transform(df_test['airline_sentiment'])\n",
    "\n",
    "# y_train = df_train['airline_sentiment']\n",
    "# y_test = df_test['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'neutral', 'positive']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,3), min_df=3, max_df=0.2, strip_accents='ascii')\n",
    "\n",
    "x_train = vec.fit_transform(df_train['text'])\n",
    "x_test = vec.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00 pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000 feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000 miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18303</th>\n",
       "      <td>yvr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18304</th>\n",
       "      <td>yvr to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18305</th>\n",
       "      <td>yyz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18306</th>\n",
       "      <td>zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18307</th>\n",
       "      <td>zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18308 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token\n",
       "id              \n",
       "0             00\n",
       "1          00 pm\n",
       "2            000\n",
       "3       000 feet\n",
       "4      000 miles\n",
       "...          ...\n",
       "18303        yvr\n",
       "18304     yvr to\n",
       "18305        yyz\n",
       "18306       zero\n",
       "18307       zone\n",
       "\n",
       "[18308 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vec.vocabulary_.items(), columns=['token', 'id']).sort_values('id').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x18308 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 254249 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x18308 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 78977 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.848980</td>\n",
       "      <td>0.902386</td>\n",
       "      <td>0.874869</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.693023</td>\n",
       "      <td>0.576774</td>\n",
       "      <td>0.629577</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.700885</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.848980  0.902386  0.874869     2305\n",
       "neutral    0.693023  0.576774  0.629577      775\n",
       "positive   0.700885  0.682759  0.691703      580"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(fit_prior=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986338797814208"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.881349</td>\n",
       "      <td>0.873319</td>\n",
       "      <td>0.877315</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.663475</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.644090</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.668217</td>\n",
       "      <td>0.743103</td>\n",
       "      <td>0.703673</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.881349  0.873319  0.877315     2305\n",
       "neutral    0.663475  0.625806  0.644090      775\n",
       "positive   0.668217  0.743103  0.703673      580"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(fit_prior=False)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8002732240437158"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro FScore = 0.7852459016393442 @ ngram_range = (1, 1)\n",
      "Micro FScore = 0.7314207650273225 @ ngram_range = (2, 2)\n",
      "Micro FScore = 0.6344262295081967 @ ngram_range = (3, 3)\n",
      "Micro FScore = 0.6418032786885246 @ ngram_range = (4, 4)\n",
      "Micro FScore = 0.6398907103825137 @ ngram_range = (5, 5)\n",
      "Micro FScore = 0.6377049180327868 @ ngram_range = (6, 6)\n",
      "Micro FScore = 0.6360655737704918 @ ngram_range = (7, 7)\n",
      "Micro FScore = 0.6352459016393442 @ ngram_range = (8, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarek/anaconda3/envs/scikitbook/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "micro_fscores = []\n",
    "\n",
    "for ngram_range in [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8)]:\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        CountVectorizer(ngram_range=ngram_range, min_df=3, max_df=0.2, strip_accents='ascii'),\n",
    "        MultinomialNB(fit_prior=False)\n",
    "    )\n",
    "\n",
    "    pipeline.fit(df_train['text'], y_train)\n",
    "    y_test_pred =  pipeline.predict(df_test['text'])\n",
    "\n",
    "    p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "    micro_fscore = precision_recall_fscore_support(y_test, y_test_pred, average='micro')[2]\n",
    "\n",
    "    print(f'Micro FScore = {micro_fscore} @ ngram_range = {ngram_range}')\n",
    "    \n",
    "    micro_fscores.append([ngram_range[-1], micro_fscore])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "pd.DataFrame(\n",
    "    micro_fscores,\n",
    "    columns=['ngram', 'Micro FScore']\n",
    ").set_index('ngram')['Micro FScore'].plot(\n",
    "    title='Micro FScore vs ngram',\n",
    "    color='k',\n",
    "    kind='bar',\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarek/anaconda3/envs/scikitbook/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for max_df in [.01, .05, .1, .2, .4, .8]:\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        CountVectorizer(ngram_range=(4,4), min_df=3, max_df=max_df, strip_accents='ascii'),\n",
    "        MultinomialNB(fit_prior=False, alpha=1)\n",
    "    )\n",
    "\n",
    "    pipeline.fit(df_train['text'], y_train)\n",
    "    y_test_pred =  pipeline.predict(df_test['text'])\n",
    "\n",
    "    p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "    \n",
    "    precision_score = [f'{max_df}']\n",
    "    precision_score.extend(p)\n",
    "    \n",
    "    recall_score = [f'{max_df}']\n",
    "    recall_score.extend(r)\n",
    "    \n",
    "    precision_scores.append(precision_score)\n",
    "    recall_scores.append(recall_score)\n",
    "    \n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "pd.DataFrame(\n",
    "    precision_scores,\n",
    "    columns=['alpha', 'Precision(negative)', 'Precision(neutral)', 'Precision(positive)']\n",
    ").set_index('alpha').plot(\n",
    "    title='Precision vs max_df',\n",
    "    # color='k',\n",
    "    kind='line',\n",
    "    ylim=(0,1),\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "pd.DataFrame(\n",
    "    recall_scores,\n",
    "    columns=['alpha', 'Recall(negative)', 'Recall(neutral)', 'Recall(positive)']\n",
    ").set_index('alpha').plot(\n",
    "    title='Recall vs max_df',\n",
    "    # color='k',\n",
    "    kind='line',\n",
    "    ylim=(0,1),\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,3), min_df=3, max_df=0.2, binary=True, strip_accents='ascii')\n",
    "\n",
    "x_train = vec.fit_transform(df_train['text'])\n",
    "x_test = vec.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.891244</td>\n",
       "      <td>0.851982</td>\n",
       "      <td>0.871171</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.611857</td>\n",
       "      <td>0.688917</td>\n",
       "      <td>0.648104</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.891244  0.851982  0.871171     2270\n",
       "neutral    0.611857  0.688917  0.648104      794\n",
       "positive   0.691275  0.691275  0.691275      596"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB(fit_prior=False)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904371584699453"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab = pd.DataFrame(vec.vocabulary_.items(), columns=['token', 'id']).sort_values('id').set_index('id')\n",
    "\n",
    "c1, c2, c3 = clf.coef_\n",
    "\n",
    "df_vocab['negative_coef'] = c1\n",
    "df_vocab['neutral_coef'] = c2\n",
    "df_vocab['positive_coef'] = c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>negative_coef</th>\n",
       "      <th>neutral_coef</th>\n",
       "      <th>positive_coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9710</th>\n",
       "      <td>my</td>\n",
       "      <td>-1.481894</td>\n",
       "      <td>-1.938568</td>\n",
       "      <td>-2.031432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>is</td>\n",
       "      <td>-1.597212</td>\n",
       "      <td>-1.897264</td>\n",
       "      <td>-2.378303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>in</td>\n",
       "      <td>-1.764071</td>\n",
       "      <td>-2.000700</td>\n",
       "      <td>-2.075492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>of</td>\n",
       "      <td>-1.869056</td>\n",
       "      <td>-2.246535</td>\n",
       "      <td>-2.330675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>it</td>\n",
       "      <td>-1.869056</td>\n",
       "      <td>-2.056728</td>\n",
       "      <td>-2.084542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>not</td>\n",
       "      <td>-1.994845</td>\n",
       "      <td>-3.070874</td>\n",
       "      <td>-3.452818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18425</th>\n",
       "      <td>your</td>\n",
       "      <td>-2.000178</td>\n",
       "      <td>-2.973019</td>\n",
       "      <td>-2.296386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>me</td>\n",
       "      <td>-2.006616</td>\n",
       "      <td>-2.288382</td>\n",
       "      <td>-2.279673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>southwestair</td>\n",
       "      <td>-2.030582</td>\n",
       "      <td>-1.525103</td>\n",
       "      <td>-1.430798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13941</th>\n",
       "      <td>that</td>\n",
       "      <td>-2.052880</td>\n",
       "      <td>-2.545206</td>\n",
       "      <td>-2.618357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10149</th>\n",
       "      <td>no</td>\n",
       "      <td>-2.057400</td>\n",
       "      <td>-3.312886</td>\n",
       "      <td>-3.586349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6684</th>\n",
       "      <td>have</td>\n",
       "      <td>-2.086121</td>\n",
       "      <td>-2.359208</td>\n",
       "      <td>-2.750782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17048</th>\n",
       "      <td>was</td>\n",
       "      <td>-2.149883</td>\n",
       "      <td>-3.070874</td>\n",
       "      <td>-2.467534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>jetblue</td>\n",
       "      <td>-2.211362</td>\n",
       "      <td>-1.476503</td>\n",
       "      <td>-1.489208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>can</td>\n",
       "      <td>-2.223322</td>\n",
       "      <td>-1.969152</td>\n",
       "      <td>-3.201504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17787</th>\n",
       "      <td>with</td>\n",
       "      <td>-2.228684</td>\n",
       "      <td>-2.539697</td>\n",
       "      <td>-2.494563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>at</td>\n",
       "      <td>-2.247680</td>\n",
       "      <td>-2.753271</td>\n",
       "      <td>-2.565515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14726</th>\n",
       "      <td>this</td>\n",
       "      <td>-2.257316</td>\n",
       "      <td>-2.681108</td>\n",
       "      <td>-2.633983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>but</td>\n",
       "      <td>-2.276869</td>\n",
       "      <td>-2.907421</td>\n",
       "      <td>-3.147436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>get</td>\n",
       "      <td>-2.282527</td>\n",
       "      <td>-2.578917</td>\n",
       "      <td>-2.967310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  negative_coef  neutral_coef  positive_coef\n",
       "id                                                             \n",
       "9710             my      -1.481894     -1.938568      -2.031432\n",
       "7784             is      -1.597212     -1.897264      -2.378303\n",
       "7481             in      -1.764071     -2.000700      -2.075492\n",
       "10566            of      -1.869056     -2.246535      -2.330675\n",
       "8034             it      -1.869056     -2.056728      -2.084542\n",
       "10289           not      -1.994845     -3.070874      -3.452818\n",
       "18425          your      -2.000178     -2.973019      -2.296386\n",
       "9245             me      -2.006616     -2.288382      -2.279673\n",
       "13176  southwestair      -2.030582     -1.525103      -1.430798\n",
       "13941          that      -2.052880     -2.545206      -2.618357\n",
       "10149            no      -2.057400     -3.312886      -3.586349\n",
       "6684           have      -2.086121     -2.359208      -2.750782\n",
       "17048           was      -2.149883     -3.070874      -2.467534\n",
       "8239        jetblue      -2.211362     -1.476503      -1.489208\n",
       "2873            can      -2.223322     -1.969152      -3.201504\n",
       "17787          with      -2.228684     -2.539697      -2.494563\n",
       "1807             at      -2.247680     -2.753271      -2.565515\n",
       "14726          this      -2.257316     -2.681108      -2.633983\n",
       "2675            but      -2.276869     -2.907421      -3.147436\n",
       "6125            get      -2.282527     -2.578917      -2.967310"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocab.sort_values('negative_coef', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>negative_coef</th>\n",
       "      <th>neutral_coef</th>\n",
       "      <th>positive_coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>thanks</td>\n",
       "      <td>-3.385404</td>\n",
       "      <td>-2.973019</td>\n",
       "      <td>-1.360072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>southwestair</td>\n",
       "      <td>-2.030582</td>\n",
       "      <td>-1.525103</td>\n",
       "      <td>-1.430798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>jetblue</td>\n",
       "      <td>-2.211362</td>\n",
       "      <td>-1.476503</td>\n",
       "      <td>-1.489208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>thank</td>\n",
       "      <td>-4.651070</td>\n",
       "      <td>-3.851883</td>\n",
       "      <td>-1.697426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>thank you</td>\n",
       "      <td>-4.763187</td>\n",
       "      <td>-3.915062</td>\n",
       "      <td>-1.748070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9710</th>\n",
       "      <td>my</td>\n",
       "      <td>-1.481894</td>\n",
       "      <td>-1.938568</td>\n",
       "      <td>-2.031432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>in</td>\n",
       "      <td>-1.764071</td>\n",
       "      <td>-2.000700</td>\n",
       "      <td>-2.075492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>it</td>\n",
       "      <td>-1.869056</td>\n",
       "      <td>-2.056728</td>\n",
       "      <td>-2.084542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>me</td>\n",
       "      <td>-2.006616</td>\n",
       "      <td>-2.288382</td>\n",
       "      <td>-2.279673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18425</th>\n",
       "      <td>your</td>\n",
       "      <td>-2.000178</td>\n",
       "      <td>-2.973019</td>\n",
       "      <td>-2.296386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>of</td>\n",
       "      <td>-1.869056</td>\n",
       "      <td>-2.246535</td>\n",
       "      <td>-2.330675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>co</td>\n",
       "      <td>-3.084983</td>\n",
       "      <td>-1.808809</td>\n",
       "      <td>-2.348271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>thanks for</td>\n",
       "      <td>-4.070040</td>\n",
       "      <td>-5.104646</td>\n",
       "      <td>-2.378303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>is</td>\n",
       "      <td>-1.597212</td>\n",
       "      <td>-1.897264</td>\n",
       "      <td>-2.378303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>great</td>\n",
       "      <td>-4.713591</td>\n",
       "      <td>-5.178754</td>\n",
       "      <td>-2.396765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>http</td>\n",
       "      <td>-3.120413</td>\n",
       "      <td>-1.849300</td>\n",
       "      <td>-2.409265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>http co</td>\n",
       "      <td>-3.120413</td>\n",
       "      <td>-1.849300</td>\n",
       "      <td>-2.409265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17048</th>\n",
       "      <td>was</td>\n",
       "      <td>-2.149883</td>\n",
       "      <td>-3.070874</td>\n",
       "      <td>-2.467534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17787</th>\n",
       "      <td>with</td>\n",
       "      <td>-2.228684</td>\n",
       "      <td>-2.539697</td>\n",
       "      <td>-2.494563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13005</th>\n",
       "      <td>so</td>\n",
       "      <td>-2.795720</td>\n",
       "      <td>-3.080264</td>\n",
       "      <td>-2.550916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  negative_coef  neutral_coef  positive_coef\n",
       "id                                                             \n",
       "13892        thanks      -3.385404     -2.973019      -1.360072\n",
       "13176  southwestair      -2.030582     -1.525103      -1.430798\n",
       "8239        jetblue      -2.211362     -1.476503      -1.489208\n",
       "13869         thank      -4.651070     -3.851883      -1.697426\n",
       "13873     thank you      -4.763187     -3.915062      -1.748070\n",
       "9710             my      -1.481894     -1.938568      -2.031432\n",
       "7481             in      -1.764071     -2.000700      -2.075492\n",
       "8034             it      -1.869056     -2.056728      -2.084542\n",
       "9245             me      -2.006616     -2.288382      -2.279673\n",
       "18425          your      -2.000178     -2.973019      -2.296386\n",
       "10566            of      -1.869056     -2.246535      -2.330675\n",
       "3388             co      -3.084983     -1.808809      -2.348271\n",
       "13898    thanks for      -4.070040     -5.104646      -2.378303\n",
       "7784             is      -1.597212     -1.897264      -2.378303\n",
       "6458          great      -4.713591     -5.178754      -2.396765\n",
       "7333           http      -3.120413     -1.849300      -2.409265\n",
       "7334        http co      -3.120413     -1.849300      -2.409265\n",
       "17048           was      -2.149883     -3.070874      -2.467534\n",
       "17787          with      -2.228684     -2.539697      -2.494563\n",
       "13005            so      -2.795720     -3.080264      -2.550916"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocab.sort_values('positive_coef', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarek/anaconda3/envs/scikitbook/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.854202</td>\n",
       "      <td>0.895595</td>\n",
       "      <td>0.874409</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.645638</td>\n",
       "      <td>0.605793</td>\n",
       "      <td>0.625081</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.749533</td>\n",
       "      <td>0.672819</td>\n",
       "      <td>0.709107</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.854202  0.895595  0.874409     2270\n",
       "neutral    0.645638  0.605793  0.625081      794\n",
       "positive   0.749533  0.672819  0.709107      596"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964480874316942"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,3), sublinear_tf=True)\n",
    "\n",
    "x_train = vec.fit_transform(df_train['text'])\n",
    "x_test = vec.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.804869</td>\n",
       "      <td>0.917621</td>\n",
       "      <td>0.857555</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.648551</td>\n",
       "      <td>0.450882</td>\n",
       "      <td>0.531947</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.694231</td>\n",
       "      <td>0.605705</td>\n",
       "      <td>0.646953</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.804869  0.917621  0.857555     2270\n",
       "neutral    0.648551  0.450882  0.531947      794\n",
       "positive   0.694231  0.605705  0.646953      596"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(fit_prior=False, alpha=0.001)\n",
    "clf.fit(x_train, y_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7655737704918033"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocab = pd.DataFrame(vec.vocabulary_.items(), columns=['token', 'id']).sort_values('id').set_index('id')\n",
    "\n",
    "c1, c2, c3 = clf.coef_\n",
    "\n",
    "df_vocab['negative_coef'] = c1\n",
    "df_vocab['neutral_coef'] = c2\n",
    "df_vocab['positive_coef'] = c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>negative_coef</th>\n",
       "      <th>neutral_coef</th>\n",
       "      <th>positive_coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191557</th>\n",
       "      <td>to</td>\n",
       "      <td>-5.915192</td>\n",
       "      <td>-5.828423</td>\n",
       "      <td>-6.100844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181012</th>\n",
       "      <td>the</td>\n",
       "      <td>-6.116753</td>\n",
       "      <td>-6.152994</td>\n",
       "      <td>-5.871366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202738</th>\n",
       "      <td>united</td>\n",
       "      <td>-6.232380</td>\n",
       "      <td>-6.088073</td>\n",
       "      <td>-6.012418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68961</th>\n",
       "      <td>flight</td>\n",
       "      <td>-6.257911</td>\n",
       "      <td>-6.453387</td>\n",
       "      <td>-6.662051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>and</td>\n",
       "      <td>-6.294188</td>\n",
       "      <td>-6.808669</td>\n",
       "      <td>-6.513998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138807</th>\n",
       "      <td>on</td>\n",
       "      <td>-6.297872</td>\n",
       "      <td>-6.328405</td>\n",
       "      <td>-6.743613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208293</th>\n",
       "      <td>usairways</td>\n",
       "      <td>-6.299983</td>\n",
       "      <td>-6.626311</td>\n",
       "      <td>-6.446595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226678</th>\n",
       "      <td>you</td>\n",
       "      <td>-6.341896</td>\n",
       "      <td>-6.138289</td>\n",
       "      <td>-5.509187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74982</th>\n",
       "      <td>for</td>\n",
       "      <td>-6.352966</td>\n",
       "      <td>-6.487227</td>\n",
       "      <td>-6.033189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126168</th>\n",
       "      <td>my</td>\n",
       "      <td>-6.383634</td>\n",
       "      <td>-6.593639</td>\n",
       "      <td>-6.672172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14771</th>\n",
       "      <td>americanair</td>\n",
       "      <td>-6.429247</td>\n",
       "      <td>-6.349866</td>\n",
       "      <td>-6.194243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101724</th>\n",
       "      <td>is</td>\n",
       "      <td>-6.456029</td>\n",
       "      <td>-6.510543</td>\n",
       "      <td>-7.027878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97922</th>\n",
       "      <td>in</td>\n",
       "      <td>-6.647387</td>\n",
       "      <td>-6.627039</td>\n",
       "      <td>-6.725352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104315</th>\n",
       "      <td>it</td>\n",
       "      <td>-6.663548</td>\n",
       "      <td>-6.587010</td>\n",
       "      <td>-6.556328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135855</th>\n",
       "      <td>of</td>\n",
       "      <td>-6.701393</td>\n",
       "      <td>-6.860115</td>\n",
       "      <td>-6.940360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132673</th>\n",
       "      <td>not</td>\n",
       "      <td>-6.706910</td>\n",
       "      <td>-7.565005</td>\n",
       "      <td>-8.038431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229345</th>\n",
       "      <td>your</td>\n",
       "      <td>-6.727950</td>\n",
       "      <td>-7.452219</td>\n",
       "      <td>-6.773576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131015</th>\n",
       "      <td>no</td>\n",
       "      <td>-6.732537</td>\n",
       "      <td>-7.610601</td>\n",
       "      <td>-8.034712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119930</th>\n",
       "      <td>me</td>\n",
       "      <td>-6.764400</td>\n",
       "      <td>-6.753629</td>\n",
       "      <td>-6.827512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179531</th>\n",
       "      <td>that</td>\n",
       "      <td>-6.814248</td>\n",
       "      <td>-7.051446</td>\n",
       "      <td>-7.083816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token  negative_coef  neutral_coef  positive_coef\n",
       "id                                                             \n",
       "191557           to      -5.915192     -5.828423      -6.100844\n",
       "181012          the      -6.116753     -6.152994      -5.871366\n",
       "202738       united      -6.232380     -6.088073      -6.012418\n",
       "68961        flight      -6.257911     -6.453387      -6.662051\n",
       "18665           and      -6.294188     -6.808669      -6.513998\n",
       "138807           on      -6.297872     -6.328405      -6.743613\n",
       "208293    usairways      -6.299983     -6.626311      -6.446595\n",
       "226678          you      -6.341896     -6.138289      -5.509187\n",
       "74982           for      -6.352966     -6.487227      -6.033189\n",
       "126168           my      -6.383634     -6.593639      -6.672172\n",
       "14771   americanair      -6.429247     -6.349866      -6.194243\n",
       "101724           is      -6.456029     -6.510543      -7.027878\n",
       "97922            in      -6.647387     -6.627039      -6.725352\n",
       "104315           it      -6.663548     -6.587010      -6.556328\n",
       "135855           of      -6.701393     -6.860115      -6.940360\n",
       "132673          not      -6.706910     -7.565005      -8.038431\n",
       "229345         your      -6.727950     -7.452219      -6.773576\n",
       "131015           no      -6.732537     -7.610601      -8.034712\n",
       "119930           me      -6.764400     -6.753629      -6.827512\n",
       "179531         that      -6.814248     -7.051446      -7.083816"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocab.sort_values('negative_coef', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "reload(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10980/10980 [02:18<00:00, 79.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3660/3660 [00:50<00:00, 73.01it/s] \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "class WordEmbeddingVectorizer:\n",
    "    \n",
    "    def __init__(self, language_model='en_core_web_md'):\n",
    "        self.nlp = spacy.load(language_model)\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        return pd.Series(x).progress_apply(\n",
    "            lambda doc: self.nlp(doc).vector.tolist()\n",
    "        ).values.tolist()\n",
    "    \n",
    "    def fit_transform(self, x, y=None):\n",
    "        return self.transform(x)\n",
    "    \n",
    "\n",
    "vec = WordEmbeddingVectorizer()\n",
    "x_train_w2v = vec.transform(df_train['text'])\n",
    "x_test_w2v = vec.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.846433</td>\n",
       "      <td>0.911063</td>\n",
       "      <td>0.877560</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.653614</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.603197</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.724272</td>\n",
       "      <td>0.643103</td>\n",
       "      <td>0.681279</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.846433  0.911063  0.877560     2305\n",
       "neutral    0.653614  0.560000  0.603197      775\n",
       "positive   0.724272  0.643103  0.681279      580"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# clf = SGDClassifier(loss='log', max_iter=10000, class_weight='balanced')\n",
    "clf = LogisticRegression(max_iter=10000, class_weight=None)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train_w2v)\n",
    "x_test_scaled = scaler.transform(x_test_w2v)\n",
    "\n",
    "clf.fit(x_train_scaled, y_train)\n",
    "y_test_pred = clf.predict(x_test_scaled)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7942622950819672"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.744674</td>\n",
       "      <td>0.940130</td>\n",
       "      <td>0.831064</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.671779</td>\n",
       "      <td>0.282581</td>\n",
       "      <td>0.397820</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.667453</td>\n",
       "      <td>0.487931</td>\n",
       "      <td>0.563745</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall         F  Support\n",
       "negative   0.744674  0.940130  0.831064     2305\n",
       "neutral    0.671779  0.282581  0.397820      775\n",
       "positive   0.667453  0.487931  0.563745      580"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "\n",
    "clf.fit(x_train_w2v, y_train)\n",
    "y_test_pred = clf.predict(x_test_w2v)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'Precision': p,\n",
    "        'Recall': r,\n",
    "        'F': f,\n",
    "        'Support': s,\n",
    "    },\n",
    "    index =le.classes_.tolist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292349726775956"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, y_test_pred, average='micro')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELMo and BERT can generate different word embeddings for a word that captures the context of a word - \n",
    "# that is its position in a sentence.\n",
    "# https://www.quora.com/What-are-the-main-differences-between-the-word-embeddings-of-ELMo-BERT-Word2vec-and-GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
